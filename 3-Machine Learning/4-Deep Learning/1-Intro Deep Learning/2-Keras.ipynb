{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(units=300, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=100, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(units=300, activation='relu'),\n",
    "    keras.layers.Dense(units=100, activation='relu'),\n",
    "    keras.layers.Dense(units=10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001EF95C2C460>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1ef96ae0ee0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1ef95c2c460>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1ef95c584c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1ef95c58ac0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n"
     ]
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(), # optimizer = 'sgd'\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(), # \"sparse_categorical_crossentropy\"\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.9041 - accuracy: 0.7691 - val_loss: 0.4091 - val_accuracy: 0.8912\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3847 - accuracy: 0.8931 - val_loss: 0.3132 - val_accuracy: 0.9130\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3171 - accuracy: 0.9103 - val_loss: 0.2723 - val_accuracy: 0.9234\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2803 - accuracy: 0.9208 - val_loss: 0.2493 - val_accuracy: 0.9289\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2538 - accuracy: 0.9284 - val_loss: 0.2277 - val_accuracy: 0.9358\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2324 - accuracy: 0.9340 - val_loss: 0.2142 - val_accuracy: 0.9398\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2154 - accuracy: 0.9387 - val_loss: 0.2043 - val_accuracy: 0.9449\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2001 - accuracy: 0.9437 - val_loss: 0.1858 - val_accuracy: 0.9494\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1872 - accuracy: 0.9469 - val_loss: 0.1775 - val_accuracy: 0.9509\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1752 - accuracy: 0.9502 - val_loss: 0.1665 - val_accuracy: 0.9545\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1645 - accuracy: 0.9535 - val_loss: 0.1591 - val_accuracy: 0.9579\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1552 - accuracy: 0.9556 - val_loss: 0.1531 - val_accuracy: 0.9577\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1469 - accuracy: 0.9583 - val_loss: 0.1461 - val_accuracy: 0.9607\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1390 - accuracy: 0.9607 - val_loss: 0.1393 - val_accuracy: 0.9629\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.1318 - accuracy: 0.9634 - val_loss: 0.1357 - val_accuracy: 0.9636\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val) # Tb argumento validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1255 - accuracy: 0.9646 - val_loss: 0.1351 - val_accuracy: 0.9631\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1197 - accuracy: 0.9667 - val_loss: 0.1281 - val_accuracy: 0.9637\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1143 - accuracy: 0.9681 - val_loss: 0.1237 - val_accuracy: 0.9656\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1090 - accuracy: 0.9696 - val_loss: 0.1215 - val_accuracy: 0.9654\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1042 - accuracy: 0.9710 - val_loss: 0.1168 - val_accuracy: 0.9660\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0998 - accuracy: 0.9727 - val_loss: 0.1154 - val_accuracy: 0.9676\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0958 - accuracy: 0.9737 - val_loss: 0.1124 - val_accuracy: 0.9662\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.1121 - val_accuracy: 0.9673\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0880 - accuracy: 0.9762 - val_loss: 0.1070 - val_accuracy: 0.9701\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0848 - accuracy: 0.9770 - val_loss: 0.1045 - val_accuracy: 0.9701\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.1059 - val_accuracy: 0.9694\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0783 - accuracy: 0.9785 - val_loss: 0.1003 - val_accuracy: 0.9717\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0754 - accuracy: 0.9798 - val_loss: 0.0986 - val_accuracy: 0.9725\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0726 - accuracy: 0.9803 - val_loss: 0.0986 - val_accuracy: 0.9724\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0700 - accuracy: 0.9816 - val_loss: 0.0975 - val_accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef97d0cd30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val) # Tb argumento validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9041219353675842,\n",
       "  0.3846908509731293,\n",
       "  0.31708410382270813,\n",
       "  0.28025078773498535,\n",
       "  0.2538030743598938,\n",
       "  0.23244954645633698,\n",
       "  0.21541529893875122,\n",
       "  0.20005124807357788,\n",
       "  0.18715029954910278,\n",
       "  0.1751769334077835,\n",
       "  0.1645427793264389,\n",
       "  0.15522031486034393,\n",
       "  0.14693637192249298,\n",
       "  0.13902147114276886,\n",
       "  0.13176655769348145],\n",
       " 'accuracy': [0.7690799832344055,\n",
       "  0.893060028553009,\n",
       "  0.9102799892425537,\n",
       "  0.9208400249481201,\n",
       "  0.9284200072288513,\n",
       "  0.9340400099754333,\n",
       "  0.9386799931526184,\n",
       "  0.9436799883842468,\n",
       "  0.9469000101089478,\n",
       "  0.9502400159835815,\n",
       "  0.953540027141571,\n",
       "  0.9556400179862976,\n",
       "  0.958299994468689,\n",
       "  0.9607399702072144,\n",
       "  0.9633600115776062],\n",
       " 'val_loss': [0.4090692102909088,\n",
       "  0.3131576478481293,\n",
       "  0.27233070135116577,\n",
       "  0.24932922422885895,\n",
       "  0.22767695784568787,\n",
       "  0.21418434381484985,\n",
       "  0.20429934561252594,\n",
       "  0.1858399659395218,\n",
       "  0.17748475074768066,\n",
       "  0.16653725504875183,\n",
       "  0.15909309685230255,\n",
       "  0.153065025806427,\n",
       "  0.1461041420698166,\n",
       "  0.13927610218524933,\n",
       "  0.13566458225250244],\n",
       " 'val_accuracy': [0.8912000060081482,\n",
       "  0.9129999876022339,\n",
       "  0.9233999848365784,\n",
       "  0.9289000034332275,\n",
       "  0.9358000159263611,\n",
       "  0.9398000240325928,\n",
       "  0.9448999762535095,\n",
       "  0.949400007724762,\n",
       "  0.9509000182151794,\n",
       "  0.9545000195503235,\n",
       "  0.9578999876976013,\n",
       "  0.9577000141143799,\n",
       "  0.9606999754905701,\n",
       "  0.9628999829292297,\n",
       "  0.9635999798774719]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.12553876638412476,\n",
       "  0.11968433856964111,\n",
       "  0.11425674706697464,\n",
       "  0.10900083929300308,\n",
       "  0.10421714931726456,\n",
       "  0.09978354722261429,\n",
       "  0.0958055853843689,\n",
       "  0.09176751971244812,\n",
       "  0.08797816187143326,\n",
       "  0.0847892090678215,\n",
       "  0.08157777041196823,\n",
       "  0.07830803096294403,\n",
       "  0.07541851699352264,\n",
       "  0.07263858616352081,\n",
       "  0.07001947611570358],\n",
       " 'accuracy': [0.9646000266075134,\n",
       "  0.9667199850082397,\n",
       "  0.9681000113487244,\n",
       "  0.9695799946784973,\n",
       "  0.9709799885749817,\n",
       "  0.9727200269699097,\n",
       "  0.9737200140953064,\n",
       "  0.9750400185585022,\n",
       "  0.9761800169944763,\n",
       "  0.9769799709320068,\n",
       "  0.9779599905014038,\n",
       "  0.9785400032997131,\n",
       "  0.9798200130462646,\n",
       "  0.9802799820899963,\n",
       "  0.9816200137138367],\n",
       " 'val_loss': [0.13511070609092712,\n",
       "  0.12809577584266663,\n",
       "  0.12366896122694016,\n",
       "  0.12149587273597717,\n",
       "  0.11678148061037064,\n",
       "  0.11537183821201324,\n",
       "  0.11238675564527512,\n",
       "  0.11205312609672546,\n",
       "  0.10696402937173843,\n",
       "  0.10452702641487122,\n",
       "  0.10590362548828125,\n",
       "  0.10025197267532349,\n",
       "  0.09863896667957306,\n",
       "  0.09860485047101974,\n",
       "  0.0975068137049675],\n",
       " 'val_accuracy': [0.963100016117096,\n",
       "  0.963699996471405,\n",
       "  0.9656000137329102,\n",
       "  0.965399980545044,\n",
       "  0.9660000205039978,\n",
       "  0.9675999879837036,\n",
       "  0.9661999940872192,\n",
       "  0.9672999978065491,\n",
       "  0.9700999855995178,\n",
       "  0.9700999855995178,\n",
       "  0.9693999886512756,\n",
       "  0.9717000126838684,\n",
       "  0.9725000262260437,\n",
       "  0.9724000096321106,\n",
       "  0.9713000059127808]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9700\n",
      "test loss, test acc: [0.0972798690199852, 0.9700000286102295]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.999, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"shape\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "346/363 [===========================>..] - ETA: 0s - loss: 0.8160WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8018 - val_loss: 0.5397\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5844 - val_loss: 0.4482\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4530 - val_loss: 0.4285\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4247 - val_loss: 0.4029\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4100 - val_loss: 0.3898\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3957 - val_loss: 0.3843\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.3731\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.3648\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3573\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3531\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3471\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3469\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.3449\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3425 - val_loss: 0.3305\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3289\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3383\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3382 - val_loss: 0.3317\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3187\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.3163\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3222 - val_loss: 0.3112\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd')\n",
    "history = model.fit(X_train,\n",
    "         y_train,\n",
    "         epochs=20,\n",
    "         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33342719078063965"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8584834],\n",
       "       [1.4391313],\n",
       "       [2.7246506]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7530247],\n",
       "       [1.3425229],\n",
       "       [2.7992435]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59 , 1.843, 2.713])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Sirven para que el modelo se vaya guardando tras cada epoch, asi no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.3186\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3180 - val_loss: 0.3099\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.3103\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3029\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3103 - val_loss: 0.3146\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3079 - val_loss: 0.3303\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3106\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3064 - val_loss: 0.3028\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3053 - val_loss: 0.2980\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3034 - val_loss: 0.3016\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3009 - val_loss: 0.2903\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3023 - val_loss: 0.3065\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2987 - val_loss: 0.3009\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2955 - val_loss: 0.2934\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2951 - val_loss: 0.2847\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3023 - val_loss: 0.2952\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2947 - val_loss: 0.2908\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3002 - val_loss: 0.2911\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2977 - val_loss: 0.2875\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2911 - val_loss: 0.2908\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=20,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2918 - val_loss: 0.2886\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2894 - val_loss: 0.2952\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2898 - val_loss: 0.2869\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.2987\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2879 - val_loss: 0.2905\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2868 - val_loss: 0.2973\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2841 - val_loss: 0.2813\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2835 - val_loss: 0.2826\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.2818\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.2780\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.2854\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2979\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2810\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2771 - val_loss: 0.2871\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2800\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=5,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=20,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[checkpoint, early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/363 [..............................] - ETA: 0s - loss: 0.1286WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 12s - loss: 0.1553WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0700s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.2877\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2827 - val_loss: 0.2797\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.2752\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2793 - val_loss: 0.2805\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2812 - val_loss: 0.2823\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2798 - val_loss: 0.2744\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2775 - val_loss: 0.2771\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2772 - val_loss: 0.2817\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2773 - val_loss: 0.2857\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2762 - val_loss: 0.2876\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2758 - val_loss: 0.2764\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2764 - val_loss: 0.2706\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2736 - val_loss: 0.2714\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2736 - val_loss: 0.2704\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2724 - val_loss: 0.3161\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2729 - val_loss: 0.2746\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2733 - val_loss: 0.2723\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2754 - val_loss: 0.2978\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2725 - val_loss: 0.2712\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2711 - val_loss: 0.2794\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2708 - val_loss: 0.2685\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2710 - val_loss: 0.2875\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2714 - val_loss: 0.2801\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2690 - val_loss: 0.2673\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2723 - val_loss: 0.2737\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2681 - val_loss: 0.2764\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2684 - val_loss: 0.2891\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2689 - val_loss: 0.2693\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2718 - val_loss: 0.2744\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2672 - val_loss: 0.2731\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2704 - val_loss: 0.2691\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.2726\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2659 - val_loss: 0.2687\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2663 - val_loss: 0.2801\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2661 - val_loss: 0.2739\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2658 - val_loss: 0.2731\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2661 - val_loss: 0.2660\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2639 - val_loss: 0.2723\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2640 - val_loss: 0.2717\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2641 - val_loss: 0.2721\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2626 - val_loss: 0.2772\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.2877\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2633 - val_loss: 0.2647\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2620 - val_loss: 0.2799\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2613 - val_loss: 0.2753\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2612 - val_loss: 0.2724\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2595 - val_loss: 0.2640\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2602 - val_loss: 0.2762\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2600 - val_loss: 0.2734\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2611 - val_loss: 0.2653\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
